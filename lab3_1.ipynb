{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from collections import namedtuple\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "PUZZLE_DIM = 6\n",
    "RANDOMIZE_STEPS = 200\n",
    "action = namedtuple('Action', ['pos1', 'pos2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the goal state\n",
    "GOAL_STATE = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "GOAL_TUPLE = tuple(GOAL_STATE.flatten())\n",
    "GOAL_POSITIONS = {value: divmod(idx, PUZZLE_DIM) for idx, value in enumerate(GOAL_TUPLE)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_actions(state: np.ndarray, blank_pos: tuple[int, int]) -> list['Action']:\n",
    "    x, y = blank_pos\n",
    "    actions = []\n",
    "    if x > 0:\n",
    "        actions.append(action((x, y), (x - 1, y)))\n",
    "    if x < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x + 1, y)))\n",
    "    if y > 0:\n",
    "        actions.append(action((x, y), (x, y - 1)))\n",
    "    if y < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x, y + 1)))\n",
    "    return actions\n",
    "\n",
    "\n",
    "# Perform an action\n",
    "def do_action(state: np.ndarray, action: 'Action') -> np.ndarray:\n",
    "    new_state = state.copy()\n",
    "    new_state[action.pos1], new_state[action.pos2] = new_state[action.pos2], new_state[action.pos1]\n",
    "    return new_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heuristic: Manhattan Distance\n",
    "def manhattan_distance(state: tuple) -> int:\n",
    "    distance = 0\n",
    "    for idx, value in enumerate(state):\n",
    "        if value != 0:  # Ignore the blank tile\n",
    "            current_pos = divmod(idx, PUZZLE_DIM)\n",
    "            goal_pos = GOAL_POSITIONS[value]\n",
    "            distance += abs(current_pos[0] - goal_pos[0]) + abs(current_pos[1] - goal_pos[1])\n",
    "    return distance\n",
    "\n",
    "# A* Solver\n",
    "def a_star_solver(start_state: np.ndarray):\n",
    "    start_tuple = tuple(start_state.flatten())\n",
    "    blank_idx = start_tuple.index(0)  # Locate the blank tile\n",
    "    \n",
    "    # Priority queue: (f_score, g_score, state, blank_idx, parent)\n",
    "    frontier = [(manhattan_distance(start_tuple), 0, start_tuple, blank_idx, None)]\n",
    "    heapq.heapify(frontier)\n",
    "    \n",
    "    visited = {}\n",
    "    parents = {}\n",
    "    \n",
    "    while frontier:\n",
    "        f_score, g_score, current_state, blank_idx, parent = heapq.heappop(frontier)\n",
    "        \n",
    "        if current_state in visited and visited[current_state] <= g_score:\n",
    "            continue\n",
    "        visited[current_state] = g_score\n",
    "        parents[current_state] = parent\n",
    "        \n",
    "        if current_state == GOAL_TUPLE:\n",
    "            return reconstruct_path(parents, current_state)  # Found the goal\n",
    "        \n",
    "        current_state_np = np.array(current_state).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "        blank_pos = divmod(blank_idx, PUZZLE_DIM)\n",
    "        for action in available_actions(current_state_np, blank_pos):\n",
    "            new_state_np = do_action(current_state_np, action)\n",
    "            new_state = tuple(new_state_np.flatten())\n",
    "            new_blank_idx = action.pos2[0] * PUZZLE_DIM + action.pos2[1]  # Convert to flat index\n",
    "            \n",
    "            if new_state not in visited or visited[new_state] > g_score + 1:\n",
    "                heapq.heappush(frontier, (\n",
    "                    g_score + 1 + manhattan_distance(new_state),  # f = g + h\n",
    "                    g_score + 1,  # g = cost so far\n",
    "                    new_state,\n",
    "                    new_blank_idx,\n",
    "                    current_state\n",
    "                ))\n",
    "    return None\n",
    "\n",
    "# Reconstruct the path from the goal to the start\n",
    "def reconstruct_path(parents, state):\n",
    "    path = []\n",
    "    while state is not None:\n",
    "        path.append(state)\n",
    "        state = parents[state]\n",
    "    return path[::-1]  # Reverse to get the path from start to goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_20032\\2508324243.py:3: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  blank_pos = tuple(map(int, np.where(state == 0)))  # Initial blank tile position\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20dd65990304cd49366de2f9240c4f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Randomizing:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start State:\n",
      " [[ 1  2  3  4 10  5]\n",
      " [ 7  8 15  9  6 11]\n",
      " [13 20 16 17 23 21]\n",
      " [19 26 14 18 12  0]\n",
      " [31 25 27 29 24 35]\n",
      " [32 28 34 30 33 22]]\n"
     ]
    }
   ],
   "source": [
    "# Randomize the initial state\n",
    "state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "blank_pos = tuple(map(int, np.where(state == 0)))  # Initial blank tile position\n",
    "\n",
    "for r in tqdm(range(RANDOMIZE_STEPS), desc='Randomizing'):\n",
    "    actions = available_actions(state, blank_pos)  # Pass blank_pos\n",
    "    chosen_action = choice(actions)               # Randomly pick an action\n",
    "    state = do_action(state, chosen_action)       # Perform the action\n",
    "    blank_pos = chosen_action.pos2                # Update blank tile position\n",
    "\n",
    "# Solve the puzzle\n",
    "print(\"Start State:\\n\", state)\n",
    "solution_path = a_star_solver(state)\n",
    "if solution_path:\n",
    "    print(f\"Solution found in {len(solution_path) - 1} moves!\")\n",
    "else:\n",
    "    print(\"No solution exists.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
