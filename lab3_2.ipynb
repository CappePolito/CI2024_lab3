{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from collections import namedtuple\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "PUZZLE_DIM = 4\n",
    "RANDOMIZE_STEPS = 10000\n",
    "action = namedtuple('Action', ['pos1', 'pos2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define goal state and helpers\n",
    "GOAL_STATE = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "GOAL_POSITIONS = {value: divmod(idx, PUZZLE_DIM) for idx, value in enumerate(GOAL_STATE.flatten())}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_actions(state: np.ndarray, blank_pos: tuple[int, int]) -> list['Action']:\n",
    "    x, y = blank_pos\n",
    "    actions = []\n",
    "    if x > 0:\n",
    "        actions.append(action((x, y), (x - 1, y)))\n",
    "    if x < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x + 1, y)))\n",
    "    if y > 0:\n",
    "        actions.append(action((x, y), (x, y - 1)))\n",
    "    if y < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x, y + 1)))\n",
    "    return actions\n",
    "\n",
    "# Perform an action\n",
    "def do_action(state: np.ndarray, action: 'Action') -> np.ndarray:\n",
    "    new_state = state.copy()\n",
    "    new_state[action.pos1], new_state[action.pos2] = new_state[action.pos2], new_state[action.pos1]\n",
    "    return new_state\n",
    "\n",
    "def state_to_bytes(state: np.ndarray) -> bytes:\n",
    "    return state.flatten().tobytes()\n",
    "\n",
    "def bytes_to_state(state_bytes: bytes) -> np.ndarray:\n",
    "    return np.frombuffer(state_bytes, dtype=int).reshape((PUZZLE_DIM, PUZZLE_DIM))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized heuristic with linear conflict\n",
    "def weighted_manhattan_with_linear_conflict(state: np.ndarray, weights=(1.5, 1.0)) -> float:\n",
    "    distance = 0\n",
    "    linear_conflict = 0\n",
    "\n",
    "    for idx, value in enumerate(state.flatten()):\n",
    "        if value == 0:\n",
    "            continue\n",
    "        current_pos = divmod(idx, PUZZLE_DIM)\n",
    "        goal_pos = GOAL_POSITIONS[value]\n",
    "        tile_weight = weights[1] if value < PUZZLE_DIM**2 // 2 else weights[0]\n",
    "        distance += tile_weight * (abs(current_pos[0] - goal_pos[0]) + abs(current_pos[1] - goal_pos[1]))\n",
    "\n",
    "        # Linear conflict\n",
    "        if current_pos[0] == goal_pos[0]:  # Same row\n",
    "            for col in range(PUZZLE_DIM):\n",
    "                neighbor = state[current_pos[0], col]\n",
    "                if neighbor != 0 and neighbor != value:\n",
    "                    neighbor_goal = GOAL_POSITIONS[neighbor]\n",
    "                    if neighbor_goal[0] == current_pos[0] and neighbor_goal[1] < goal_pos[1] and col > current_pos[1]:\n",
    "                        linear_conflict += 1\n",
    "        if current_pos[1] == goal_pos[1]:  # Same column\n",
    "            for row in range(PUZZLE_DIM):\n",
    "                neighbor = state[row, current_pos[1]]\n",
    "                if neighbor != 0 and neighbor != value:\n",
    "                    neighbor_goal = GOAL_POSITIONS[neighbor]\n",
    "                    if neighbor_goal[1] == current_pos[1] and neighbor_goal[0] < goal_pos[0] and row > current_pos[0]:\n",
    "                        linear_conflict += 1\n",
    "\n",
    "    return distance + 2 * linear_conflict\n",
    "\n",
    "def ida_star_solver(start_state: np.ndarray):\n",
    "    def search(path, g_score, threshold):\n",
    "        \"\"\"\n",
    "        Perform depth-first search up to a given cost threshold.\n",
    "        \"\"\"\n",
    "        current_state_np, blank_pos, f_score = path[-1]\n",
    "        if f_score > threshold:\n",
    "            return f_score, None\n",
    "\n",
    "        # Goal state check\n",
    "        if current_state_np.tobytes() == GOAL_STATE.tobytes():\n",
    "            return f_score, path\n",
    "\n",
    "        min_cost = float('inf')\n",
    "        for action in available_actions(current_state_np, blank_pos):\n",
    "            new_state_np = do_action(current_state_np, action)\n",
    "            new_blank_pos = action.pos2\n",
    "\n",
    "            # Avoid revisiting states in the current path\n",
    "            if any((new_state_np == state).all() for state, _, _ in path):\n",
    "                continue\n",
    "\n",
    "            h_score = weighted_manhattan_with_linear_conflict(new_state_np)\n",
    "            new_f_score = g_score + 1 + h_score\n",
    "\n",
    "            # Recurse\n",
    "            result, solution_path = search(path + [(new_state_np, new_blank_pos, new_f_score)], g_score + 1, threshold)\n",
    "            if solution_path is not None:\n",
    "                return result, solution_path\n",
    "\n",
    "            min_cost = min(min_cost, result)\n",
    "\n",
    "        return min_cost, None\n",
    "\n",
    "    # Initial heuristic and cost threshold\n",
    "    blank_idx = start_state.flatten().tolist().index(0)\n",
    "    blank_pos = divmod(blank_idx, PUZZLE_DIM)\n",
    "    h_score = weighted_manhattan_with_linear_conflict(start_state)\n",
    "    threshold = h_score\n",
    "    path = [(start_state, blank_pos, h_score)]\n",
    "\n",
    "    total_actions_evaluated = 0\n",
    "    while True:\n",
    "        total_actions_evaluated += 1\n",
    "        result, solution_path = search(path, 0, threshold)\n",
    "        if solution_path is not None:\n",
    "            return solution_path, total_actions_evaluated\n",
    "        if result == float('inf'):\n",
    "            return None, total_actions_evaluated\n",
    "        threshold = result\n",
    "\n",
    "\n",
    "        \n",
    "def reconstruct_path(parents, state_hash):\n",
    "    path = []\n",
    "    while state_hash is not None:\n",
    "        path.append(state_hash)\n",
    "        state_hash, state_bytes = parents[state_hash]\n",
    "    return path[::-1], state_bytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_18424\\2053727506.py:3: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  blank_pos = tuple(map(int, np.where(state == 0)))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e7f4e8916e4ca980294993ebce3564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Randomizing:   0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start State:\n",
      " [[12  4  9  5]\n",
      " [ 8  7  6 10]\n",
      " [15 11  1 14]\n",
      " [ 3  0  2 13]]\n",
      "Solution found in 68 moves!\n",
      "Final state after solving:\n",
      " [[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15  0]]\n",
      "Number of actions on solution: 68\n",
      "Total actions evaluated: 13\n",
      "Efficiency: 5.2308\n"
     ]
    }
   ],
   "source": [
    "# Randomization for start state\n",
    "state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "blank_pos = tuple(map(int, np.where(state == 0)))\n",
    "\n",
    "for r in tqdm(range(RANDOMIZE_STEPS), desc=\"Randomizing\"):\n",
    "    actions = available_actions(state, blank_pos)\n",
    "    chosen_action = choice(actions)\n",
    "    state = do_action(state, chosen_action)\n",
    "    blank_pos = chosen_action.pos2\n",
    "\n",
    "# Solve\n",
    "print(\"Start State:\\n\", state)\n",
    "solution_path, total_actions_evaluated = ida_star_solver(state)\n",
    "\n",
    "if solution_path:\n",
    "    num_actions = len(solution_path) - 1\n",
    "    efficiency = num_actions / total_actions_evaluated\n",
    "    print(f\"Solution found in {num_actions} moves!\")\n",
    "    print(\"Final state after solving:\\n\", solution_path[-1][0])\n",
    "    print(f\"Number of actions on solution: {num_actions}\")\n",
    "    print(f\"Total actions evaluated: {total_actions_evaluated}\")\n",
    "    print(f\"Efficiency: {efficiency:.4f}\")\n",
    "else:\n",
    "    print(\"No solution exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CI-2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
